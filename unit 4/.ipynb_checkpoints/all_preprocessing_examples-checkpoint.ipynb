{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236834ed",
   "metadata": {},
   "source": [
    "#### Huggingface Dataset Guide\n",
    "This is my original work becoming familiar with Huggingface datasets. The datasets themselves and the Huggingface source guides are not my work and credit goes to the respective authors, especially the Huggingface team for making this possible (Thank you).\n",
    "\n",
    "My goal is to create simpler local reference guide for my personal ease of use.\n",
    "I used this Huggingface guide as a starting point: https://huggingface.co/docs/datasets/process#map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a06dcfb",
   "metadata": {},
   "source": [
    "#### Load a datasetset's split as an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90a69e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('glue', 'mrpc', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeea57d2",
   "metadata": {},
   "source": [
    "#### The command we want to run is dataset.info, but the output is hard to read so we reformat it\n",
    "I submitted https://github.com/huggingface/datasets/issues/6495 for help since the newline characters aren't behaving correctly. \n",
    "\n",
    "Dataset.info is its own type (datasets.info.DatasetInfo).\n",
    "I want to be able to see just the features information and the number of records without the citations so I can get working. \n",
    "\n",
    "This is done with dataset.info.features and dataset.info.splits['your_split'].num_examples respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da8c6d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb57fa0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f54e59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3668"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.info.splits['train'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4fe3efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nDatasetInfo(\\n\\ndescription='GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems.', \\n\\ncitation='@inproceedings{dolan2005automatically,\\ntitle={Automatically constructing a corpus of sentential paraphrases},\\nauthor={Dolan, William B and Brockett, Chris},\\nbooktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},\\nyear={2005}}\\n\\n@inproceedings{wang2019glue,\\ntitle={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\\nauthor={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\\nnote={In the Proceedings of ICLR.},\\nyear={2019}}',\\n\\nhomepage='https://www.microsoft.com/en-us/download/details.aspx?id=52398',\\nlicense='',\\nfeatures={'sentence1': Value(dtype='string', id=None),\\n\\t\\t  'sentence2': Value(dtype='string', id=None),\\n\\t\\t  'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\\n\\t\\t  'idx': Value(dtype='int32', id=None)},\\npost_processed=None,\\nsupervised_keys=None,\\ntask_templates=None,\\nbuilder_name='glue',\\ndataset_name=None,\\nconfig_name='mrpc',\\nversion=1.0.0,\\nsplits={'train': SplitInfo(name='train',\\n\\t\\t\\t\\t\\t\\t   num_bytes=943843,\\n\\t\\t\\t\\t\\t\\t   num_examples=3668,\\n\\t\\t\\t\\t\\t\\t   shard_lengths=None,\\n\\t\\t\\t\\t\\t\\t   dataset_name='glue'),\\n\\t\\t'validation': SplitInfo(name='validation',\\n\\t\\t\\t\\t\\t\\t\\t    num_bytes=105879,\\n\\t\\t\\t\\t\\t\\t\\t    num_examples=408,\\n\\t\\t\\t\\t\\t\\t\\t    shard_lengths=None,\\n\\t\\t\\t\\t\\t\\t\\t    dataset_name='glue'),\\n\\t\\t'test': SplitInfo(name='test',\\n\\t\\t\\t\\t\\t\\t  num_bytes=442410,\\n\\t\\t\\t\\t\\t\\t  num_examples=1725,\\n\\t\\t\\t\\t\\t\\t  shard_lengths=None,\\n\\t\\t\\t\\t\\t\\t  dataset_name='glue')},\\n\\tdownload_checksums={'https://dl.fbaipublicfiles.com/glue/data/mrpc_dev_ids.tsv': {'num_bytes': 6222, 'checksum': None},\\n\\t                    'https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt': {'num_bytes': 1047044, 'checksum': None}, 'https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt': {'num_bytes': 441275, 'checksum': None}},\\ndownload_size=1494541,\\npost_processing_size=None,\\ndataset_size=1492132,\\nsize_in_bytes=2986673)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "DatasetInfo(\n",
    "\n",
    "description='GLUE, the General Language Understanding Evaluation benchmark\n",
    "(https://gluebenchmark.com/) is a collection of resources for training,\n",
    "evaluating, and analyzing natural language understanding systems.', \n",
    "\n",
    "citation='@inproceedings{dolan2005automatically,\n",
    "title={Automatically constructing a corpus of sentential paraphrases},\n",
    "author={Dolan, William B and Brockett, Chris},\n",
    "booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},\n",
    "year={2005}}\n",
    "\n",
    "@inproceedings{wang2019glue,\n",
    "title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\n",
    "author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\n",
    "note={In the Proceedings of ICLR.},\n",
    "year={2019}}',\n",
    "\n",
    "homepage='https://www.microsoft.com/en-us/download/details.aspx?id=52398',\n",
    "license='',\n",
    "features={'sentence1': Value(dtype='string', id=None),\n",
    "          'sentence2': Value(dtype='string', id=None),\n",
    "          'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n",
    "          'idx': Value(dtype='int32', id=None)},\n",
    "post_processed=None,\n",
    "supervised_keys=None,\n",
    "task_templates=None,\n",
    "builder_name='glue',\n",
    "dataset_name=None,\n",
    "config_name='mrpc',\n",
    "version=1.0.0,\n",
    "splits={'train': SplitInfo(name='train',\n",
    "                           num_bytes=943843,\n",
    "                           num_examples=3668,\n",
    "                           shard_lengths=None,\n",
    "                           dataset_name='glue'),\n",
    "        'validation': SplitInfo(name='validation',\n",
    "                                num_bytes=105879,\n",
    "                                num_examples=408,\n",
    "                                shard_lengths=None,\n",
    "                                dataset_name='glue'),\n",
    "        'test': SplitInfo(name='test',\n",
    "                          num_bytes=442410,\n",
    "                          num_examples=1725,\n",
    "                          shard_lengths=None,\n",
    "                          dataset_name='glue')},\n",
    "\n",
    "download_checksums={'https://dl.fbaipublicfiles.com/glue/data/mrpc_dev_ids.tsv': {'num_bytes': 6222,\n",
    "                                                                                  'checksum': None},\n",
    "                    'https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt': {'num_bytes': 1047044,\n",
    "                                                                                                       'checksum': None},\n",
    "                    'https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt': {'num_bytes': 441275,\n",
    "                                                                                                      'checksum': None}},\n",
    "download_size=1494541,\n",
    "post_processing_size=None,\n",
    "dataset_size=1492132,\n",
    "size_in_bytes=2986673)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da23008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "860de6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description=\"Movie Review Dataset.\\nThis is a dataset of containing 5,331 positive and 5,331 negative processed\\nsentences from Rotten Tomatoes movie reviews. This data was first used in Bo\\nPang and Lillian Lee, ``Seeing stars: Exploiting class relationships for\\nsentiment categorization with respect to rating scales.'', Proceedings of the\\nACL, 2005.\\n\", citation='@InProceedings{Pang+Lee:05a,\\n  author =       {Bo Pang and Lillian Lee},\\n  title =        {Seeing stars: Exploiting class relationships for sentiment\\n                  categorization with respect to rating scales},\\n  booktitle =    {Proceedings of the ACL},\\n  year =         2005\\n}\\n', homepage='http://www.cs.cornell.edu/people/pabo/movie-review-data/', license='', features={'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None)}, post_processed=None, supervised_keys=SupervisedKeysData(input='', output=''), task_templates=[TextClassification(task='text-classification', text_column='text', label_column='label')], builder_name='rotten_tomatoes', dataset_name='rotten_tomatoes', config_name='default', version=1.0.0, splits={'train': SplitInfo(name='train', num_bytes=1074806, num_examples=8530, shard_lengths=None, dataset_name='rotten_tomatoes'), 'validation': SplitInfo(name='validation', num_bytes=134675, num_examples=1066, shard_lengths=None, dataset_name='rotten_tomatoes'), 'test': SplitInfo(name='test', num_bytes=135968, num_examples=1066, shard_lengths=None, dataset_name='rotten_tomatoes')}, download_checksums={'https://storage.googleapis.com/seldon-datasets/sentence_polarity_v1/rt-polaritydata.tar.gz': {'num_bytes': 487770, 'checksum': None}}, download_size=487770, post_processing_size=None, dataset_size=1345449, size_in_bytes=1833219)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6133b7d2",
   "metadata": {},
   "source": [
    "#### View metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7b8d8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='GLUE, the General Language Understanding Evaluation benchmark\\n(https://gluebenchmark.com/) is a collection of resources for training,\\nevaluating, and analyzing natural language understanding systems.\\n\\n', citation='@inproceedings{dolan2005automatically,\\n  title={Automatically constructing a corpus of sentential paraphrases},\\n  author={Dolan, William B and Brockett, Chris},\\n  booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},\\n  year={2005}\\n}\\n@inproceedings{wang2019glue,\\n  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},\\n  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},\\n  note={In the Proceedings of ICLR.},\\n  year={2019}\\n}\\n', homepage='https://www.microsoft.com/en-us/download/details.aspx?id=52398', license='', features={'sentence1': Value(dtype='string', id=None), 'sentence2': Value(dtype='string', id=None), 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None), 'idx': Value(dtype='int32', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name='glue', dataset_name=None, config_name='mrpc', version=1.0.0, splits={'train': SplitInfo(name='train', num_bytes=943843, num_examples=3668, shard_lengths=None, dataset_name='glue'), 'validation': SplitInfo(name='validation', num_bytes=105879, num_examples=408, shard_lengths=None, dataset_name='glue'), 'test': SplitInfo(name='test', num_bytes=442410, num_examples=1725, shard_lengths=None, dataset_name='glue')}, download_checksums={'https://dl.fbaipublicfiles.com/glue/data/mrpc_dev_ids.tsv': {'num_bytes': 6222, 'checksum': None}, 'https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt': {'num_bytes': 1047044, 'checksum': None}, 'https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt': {'num_bytes': 441275, 'checksum': None}}, download_size=1494541, post_processing_size=None, dataset_size=1492132, size_in_bytes=2986673)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df522f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0942e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 4 columns.\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataset has\", dataset.shape[1], \"columns:\",\n",
    "     '\\n', '-' )\n",
    "      \n",
    "      \n",
    "    #  type(dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3da185b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04ed9a",
   "metadata": {},
   "source": [
    "#### Sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03bb6240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"label\"][:10]\n",
    "sorted_dataset = dataset.sort(\"label\")\n",
    "sorted_dataset[\"label\"][:10]\n",
    "sorted_dataset[\"label\"][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e8263",
   "metadata": {},
   "source": [
    "#### Shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc9e751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 1, 1, 1, 1, 1, 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_dataset = sorted_dataset.shuffle(seed=42)\n",
    "shuffled_dataset[\"label\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982175e4",
   "metadata": {},
   "source": [
    "#### Select rows by indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2106840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset = dataset.select([0, 10, 20, 30, 40, 50])\n",
    "len(small_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cbef7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
