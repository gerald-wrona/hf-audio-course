DatasetInfo(

description='GLUE, the General Language Understanding Evaluation benchmark
(https://gluebenchmark.com/) is a collection of resources for training,
evaluating, and analyzing natural language understanding systems.', 

citation='@inproceedings{dolan2005automatically,
title={Automatically constructing a corpus of sentential paraphrases},
author={Dolan, William B and Brockett, Chris},
booktitle={Proceedings of the Third International Workshop on Paraphrasing (IWP2005)},
year={2005}}

@inproceedings{wang2019glue,
title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
note={In the Proceedings of ICLR.},
year={2019}}',

homepage='https://www.microsoft.com/en-us/download/details.aspx?id=52398',
license='',
features={'sentence1': Value(dtype='string', id=None),
		  'sentence2': Value(dtype='string', id=None),
		  'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),
		  'idx': Value(dtype='int32', id=None)},
post_processed=None,
supervised_keys=None,
task_templates=None,
builder_name='glue',
dataset_name=None,
config_name='mrpc',
version=1.0.0,
splits={'train': SplitInfo(name='train',
						   num_bytes=943843,
						   num_examples=3668,
						   shard_lengths=None,
						   dataset_name='glue'),
		'validation': SplitInfo(name='validation',
							    num_bytes=105879,
							    num_examples=408,
							    shard_lengths=None,
							    dataset_name='glue'),
		'test': SplitInfo(name='test',
						  num_bytes=442410,
						  num_examples=1725,
						  shard_lengths=None,
						  dataset_name='glue')},
	download_checksums={'https://dl.fbaipublicfiles.com/glue/data/mrpc_dev_ids.tsv': {'num_bytes': 6222, 'checksum': None},
	                    'https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt': {'num_bytes': 1047044, 'checksum': None}, 'https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_test.txt': {'num_bytes': 441275, 'checksum': None}},
download_size=1494541,
post_processing_size=None,
dataset_size=1492132,
size_in_bytes=2986673)